{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "memt1iwwWvOV",
    "outputId": "aec5aa72-8e07-4e17-dbcc-38b11d3ad0f8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /aiffel/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import urllib.request\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='bs4')\n",
    "\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "rp3jQ45zWz3v"
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/sunnysai12345/News_Summary/master/news_summary_more.csv\", filename=\"news_summary_more.csv\")\n",
    "data = pd.read_csv('news_summary_more.csv', encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "FxUz8yNnW77N",
    "outputId": "9e58185a-cb78-49a3-c2fe-15fd7fc43382"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80925</th>\n",
       "      <td>SC closes 9-yr-old case against Govinda for sl...</td>\n",
       "      <td>The Supreme Court has closed a nine-year-old c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18374</th>\n",
       "      <td>Weak rupee could cost India $9.5bn more to rep...</td>\n",
       "      <td>SBI's Chief Economic Advisor Soumya Kanti Ghos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59973</th>\n",
       "      <td>Vijender to take on Commonwealth champion in n...</td>\n",
       "      <td>Vijender Singh will take on British and Common...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47504</th>\n",
       "      <td>ChaKu stabbed SA brutally: Sehwag on spinners'...</td>\n",
       "      <td>Reacting to Indian spinners Kuldeep Yadav and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5176</th>\n",
       "      <td>Virat Kohli didnÃ¢ÂÂt go over the top: Micha...</td>\n",
       "      <td>Former Australian cricketer Michael Hussey def...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72171</th>\n",
       "      <td>US blocks convoy of ISIS fighters being evacua...</td>\n",
       "      <td>A US-led coalition carried out air strikes to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83102</th>\n",
       "      <td>India hasn't been affected much by Petya attac...</td>\n",
       "      <td>Information Technology Minister Ravi Shankar P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7466</th>\n",
       "      <td>Unfair to give political colour to Bulandshahr...</td>\n",
       "      <td>Calling the violence in Bulandshahr that kille...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88127</th>\n",
       "      <td>NASA honours APJ Abdul Kalam by naming new spe...</td>\n",
       "      <td>NASA paid tribute to late President APJ Abdul ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6611</th>\n",
       "      <td>First sign of new beginning: Haasan on Assembl...</td>\n",
       "      <td>Hailing the results of the Assembly elections ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               headlines  \\\n",
       "80925  SC closes 9-yr-old case against Govinda for sl...   \n",
       "18374  Weak rupee could cost India $9.5bn more to rep...   \n",
       "59973  Vijender to take on Commonwealth champion in n...   \n",
       "47504  ChaKu stabbed SA brutally: Sehwag on spinners'...   \n",
       "5176   Virat Kohli didnÃ¢ÂÂt go over the top: Micha...   \n",
       "72171  US blocks convoy of ISIS fighters being evacua...   \n",
       "83102  India hasn't been affected much by Petya attac...   \n",
       "7466   Unfair to give political colour to Bulandshahr...   \n",
       "88127  NASA honours APJ Abdul Kalam by naming new spe...   \n",
       "6611   First sign of new beginning: Haasan on Assembl...   \n",
       "\n",
       "                                                    text  \n",
       "80925  The Supreme Court has closed a nine-year-old c...  \n",
       "18374  SBI's Chief Economic Advisor Soumya Kanti Ghos...  \n",
       "59973  Vijender Singh will take on British and Common...  \n",
       "47504  Reacting to Indian spinners Kuldeep Yadav and ...  \n",
       "5176   Former Australian cricketer Michael Hussey def...  \n",
       "72171  A US-led coalition carried out air strikes to ...  \n",
       "83102  Information Technology Minister Ravi Shankar P...  \n",
       "7466   Calling the violence in Bulandshahr that kille...  \n",
       "88127  NASA paid tribute to late President APJ Abdul ...  \n",
       "6611   Hailing the results of the Assembly elections ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "31BxjaCrXB5o",
    "outputId": "02c73785-fe78-44cd-ba1c-e3fe162fdc9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 열에서 중복을 배제한 유일한 샘플의 수 : 98360\n",
      "headlines 열에서 중복을 배제한 유일한 샘플의 수 : 98280\n"
     ]
    }
   ],
   "source": [
    "print('Text 열에서 중복을 배제한 유일한 샘플의 수 :', data['text'].nunique())\n",
    "print('headlines 열에서 중복을 배제한 유일한 샘플의 수 :', data['headlines'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qfFbbTBKX8HY",
    "outputId": "4193c6ac-1dc6-41b8-c1bf-aa9b0b0d494f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 98360\n"
     ]
    }
   ],
   "source": [
    "# inplace=True 를 설정하면 DataFrame 타입 값을 return 하지 않고 data 내부를 직접적으로 바꿉니다\n",
    "data.drop_duplicates(subset = ['text'], inplace=True)\n",
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RhnZChEMYKYJ",
    "outputId": "40729dfd-9440-49c6-bc74-60709f5eed50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "headlines    0\n",
      "text         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8ARbuatdYOVB",
    "outputId": "9a8e7ba9-5ca8-4576-bddf-65e6dc735652"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 98360\n"
     ]
    }
   ],
   "source": [
    "data.dropna(axis=0, inplace=True)\n",
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pqxQs7vGY1Fm"
   },
   "source": [
    "## 텍스트 정규화와 불용어 제거 (Headlines 는 하지 않음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lcXix5foYXP1",
    "outputId": "9bedb7f7-65a3-4bd6-e8e0-e0df77bb4bec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정규화 사전의 수:  120\n",
      "불용어 개수 : 179\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "contractions = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}\n",
    "\n",
    "print(\"정규화 사전의 수: \", len(contractions))\n",
    "\n",
    "print('불용어 개수 :', len(stopwords.words('english') ))\n",
    "print(stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "A-Rtp-juZBBF"
   },
   "outputs": [],
   "source": [
    "# 데이터 전처리 함수\n",
    "def preprocess_sentence(sentence, remove_stopwords=True):\n",
    "    sentence = sentence.lower() # 텍스트 소문자화\n",
    "    sentence = BeautifulSoup(sentence, \"lxml\").text # <br />, <a href = ...> 등의 html 태그 제거\n",
    "    sentence = re.sub(r'\\([^)]*\\)', '', sentence) # 괄호로 닫힌 문자열 (...) 제거 Ex) my husband (and myself!) for => my husband for\n",
    "    sentence = re.sub('\"','', sentence) # 쌍따옴표 \" 제거\n",
    "    sentence = ' '.join([contractions[t] if t in contractions else t for t in sentence.split(\" \")]) # 약어 정규화\n",
    "    sentence = re.sub(r\"'s\\b\",\"\", sentence) # 소유격 제거. Ex) roland's -> roland\n",
    "    sentence = re.sub(\"[^a-zA-Z]\", \" \", sentence) # 영어 외 문자(숫자, 특수문자 등) 공백으로 변환\n",
    "    sentence = re.sub('[m]{2,}', 'mm', sentence) # m이 3개 이상이면 2개로 변경. Ex) ummmmmmm yeah -> umm yeah\n",
    "\n",
    "    # 불용어 제거 (Text)\n",
    "    if remove_stopwords:\n",
    "        tokens = ' '.join(word for word in sentence.split() if not word in stopwords.words('english') if len(word) > 1)\n",
    "    # 불용어 미제거 (Summary)\n",
    "    else:\n",
    "        tokens = ' '.join(word for word in sentence.split() if len(word) > 1)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LWbAl8ZpZIHC",
    "outputId": "67cf56d3-11c6-4aab-f808-68f81849f33a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text 전처리 후 결과:  ['saurav kant alumnus upgrad iiit pg program machine learning artificial intelligence sr systems engineer infosys almost years work experience program upgrad degree career support helped transition data scientist tech mahindra salary hike upgrad online power learning powered lakh careers', 'kunal shah credit card bill payment platform cred gave users chance win free food swiggy one year pranav kaushik delhi techie bagged reward spending cred coins users get one cred coin per rupee bill paid used avail rewards brands like ixigo bookmyshow ubereats cult fit', 'new zealand defeated india wickets fourth odi hamilton thursday win first match five match odi series india lost international match rohit sharma captaincy consecutive victories dating back march match witnessed india getting seventh lowest total odi cricket history', 'aegon life iterm insurance plan customers enjoy tax benefits premiums paid save taxes plan provides life cover age years also customers options insure critical illnesses disability accidental death benefit rider life cover age years', 'speaking sexual harassment allegations rajkumar hirani sonam kapoor said known hirani many years true metoo movement get derailed metoo movement always believe woman case need reserve judgment added hirani accused assistant worked sanju']\n"
     ]
    }
   ],
   "source": [
    "# 텍스트 전처리\n",
    "clean_text = []\n",
    "for text in data['text']:\n",
    "    clean_text.append(preprocess_sentence(text))\n",
    "# 전처리 후 출력\n",
    "print(\"text 전처리 후 결과: \", clean_text[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zz9I_n70Z3de",
    "outputId": "1f61b5f6-9ae9-4764-a773-868da47fc83c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "headlines 전처리 후 결과:  ['upgrad learner switches career ml al salary hike', 'delhi techie wins free food swiggy one year cred', 'new zealand end rohit sharma led india match winning streak', 'aegon life iterm insurance plan helps customers save tax', 'known hirani yrs metoo claims true sonam']\n"
     ]
    }
   ],
   "source": [
    "# headlines 전처리\n",
    "clean_headlines = []\n",
    "\n",
    "for headlines in data['headlines']:\n",
    "    clean_headlines.append(preprocess_sentence(headlines))\n",
    "\n",
    "print(\"headlines 전처리 후 결과: \", clean_headlines[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "K6wjgECLchFG"
   },
   "outputs": [],
   "source": [
    "data['text'] = clean_text\n",
    "data['headlines'] = clean_headlines\n",
    "\n",
    "# 빈 값을 Null 값으로 변환\n",
    "data.replace('', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vmd3o426dMma",
    "outputId": "f6745457-255c-42f1-c672-b5f02282d9dc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "headlines    0\n",
       "text         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HaR0Rubkodo-",
    "outputId": "96a44d70-1f3d-4294-bebc-6732c1feb2fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 98360\n"
     ]
    }
   ],
   "source": [
    "data.dropna(axis=0, inplace=True)\n",
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qoj2y6fBdU8_"
   },
   "source": [
    "## 샘플의 최대 길이 정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "dlLgOAkedQAe",
    "outputId": "8bdce388-14d5-4f99-ec20-45337eb66249"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텍스트의 최소 길이 : 1\n",
      "텍스트의 최대 길이 : 60\n",
      "텍스트의 평균 길이 : 35.09968483123221\n",
      "요약의 최소 길이 : 1\n",
      "요약의 최대 길이 : 13\n",
      "요약의 평균 길이 : 7.136183407889386\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 길이 분포 출력\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text_len = [len(s.split()) for s in data['text']]\n",
    "headlines_len = [len(s.split()) for s in data['headlines']]\n",
    "\n",
    "print('텍스트의 최소 길이 : {}'.format(np.min(text_len)))\n",
    "print('텍스트의 최대 길이 : {}'.format(np.max(text_len)))\n",
    "print('텍스트의 평균 길이 : {}'.format(np.mean(text_len)))\n",
    "print('요약의 최소 길이 : {}'.format(np.min(headlines_len)))\n",
    "print('요약의 최대 길이 : {}'.format(np.max(headlines_len)))\n",
    "print('요약의 평균 길이 : {}'.format(np.mean(headlines_len)))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.boxplot(text_len)\n",
    "plt.title('text')\n",
    "plt.subplot(1,2,2)\n",
    "plt.boxplot(headlines_len)\n",
    "plt.title('headlines')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.title('text')\n",
    "plt.hist(text_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()\n",
    "\n",
    "plt.title('headlines')\n",
    "plt.hist(headlines_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6i2gQzDid4iR"
   },
   "source": [
    "## test와 headlines의 길이가 평균값의 고룬 분포를 이루고 있는 것으로 보여짐.\n",
    "## test의 최대길이는 40, headlines의 길이는 8로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "VH6abu0jdotD"
   },
   "outputs": [],
   "source": [
    "text_max_len = 40\n",
    "headlines_max_len = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "EhiqMpv9elBU"
   },
   "outputs": [],
   "source": [
    "def below_threshold_len(max_len, nested_list):\n",
    "  cnt = 0\n",
    "  for s in nested_list:\n",
    "    if(len(s.split()) <= max_len):\n",
    "        cnt = cnt + 1\n",
    "  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (cnt / len(nested_list))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AxLLkNjmevO7",
    "outputId": "b56ab838-3d46-43a4-ee07-92de0e1db356"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 중 길이가 40 이하인 샘플의 비율: 0.9238714924766165\n",
      "전체 샘플 중 길이가 8 이하인 샘플의 비율: 0.8925782838552258\n"
     ]
    }
   ],
   "source": [
    "below_threshold_len(text_max_len, data['text'])\n",
    "below_threshold_len(headlines_max_len,  data['headlines'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y3uFlyfrfHs6"
   },
   "source": [
    "## 90% 이상의 데이터를 가져가는것으로 확인됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z0aTsdT9eyMK",
    "outputId": "ed413fe5-3bbf-42fe-c9b4-33d3d17a0f28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 81914\n"
     ]
    }
   ],
   "source": [
    "data = data[data['text'].apply(lambda x: len(x.split()) <= text_max_len)]\n",
    "data = data[data['headlines'].apply(lambda x: len(x.split()) <= headlines_max_len)]\n",
    "\n",
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "f--aXttlfd9T",
    "outputId": "a2d4323a-f5e7-456a-baa3-de50557cedf7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "      <th>decoder_input</th>\n",
       "      <th>decoder_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>upgrad learner switches career ml al salary hike</td>\n",
       "      <td>saurav kant alumnus upgrad iiit pg program mac...</td>\n",
       "      <td>sostoken upgrad learner switches career ml al ...</td>\n",
       "      <td>upgrad learner switches career ml al salary hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>known hirani yrs metoo claims true sonam</td>\n",
       "      <td>speaking sexual harassment allegations rajkuma...</td>\n",
       "      <td>sostoken known hirani yrs metoo claims true sonam</td>\n",
       "      <td>known hirani yrs metoo claims true sonam eostoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>india get lowest odi total new zealand</td>\n",
       "      <td>india recorded lowest odi total new zealand ge...</td>\n",
       "      <td>sostoken india get lowest odi total new zealand</td>\n",
       "      <td>india get lowest odi total new zealand eostoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>govt directs alok verma join work day retirement</td>\n",
       "      <td>weeks ex cbi director alok verma told departme...</td>\n",
       "      <td>sostoken govt directs alok verma join work day...</td>\n",
       "      <td>govt directs alok verma join work day retireme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cong wins ramgarh bypoll rajasthan takes total...</td>\n",
       "      <td>congress candidate shafia zubair ramgarh assem...</td>\n",
       "      <td>sostoken cong wins ramgarh bypoll rajasthan ta...</td>\n",
       "      <td>cong wins ramgarh bypoll rajasthan takes total...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           headlines  \\\n",
       "0   upgrad learner switches career ml al salary hike   \n",
       "4           known hirani yrs metoo claims true sonam   \n",
       "6             india get lowest odi total new zealand   \n",
       "7   govt directs alok verma join work day retirement   \n",
       "9  cong wins ramgarh bypoll rajasthan takes total...   \n",
       "\n",
       "                                                text  \\\n",
       "0  saurav kant alumnus upgrad iiit pg program mac...   \n",
       "4  speaking sexual harassment allegations rajkuma...   \n",
       "6  india recorded lowest odi total new zealand ge...   \n",
       "7  weeks ex cbi director alok verma told departme...   \n",
       "9  congress candidate shafia zubair ramgarh assem...   \n",
       "\n",
       "                                       decoder_input  \\\n",
       "0  sostoken upgrad learner switches career ml al ...   \n",
       "4  sostoken known hirani yrs metoo claims true sonam   \n",
       "6    sostoken india get lowest odi total new zealand   \n",
       "7  sostoken govt directs alok verma join work day...   \n",
       "9  sostoken cong wins ramgarh bypoll rajasthan ta...   \n",
       "\n",
       "                                      decoder_target  \n",
       "0  upgrad learner switches career ml al salary hi...  \n",
       "4  known hirani yrs metoo claims true sonam eostoken  \n",
       "6    india get lowest odi total new zealand eostoken  \n",
       "7  govt directs alok verma join work day retireme...  \n",
       "9  cong wins ramgarh bypoll rajasthan takes total...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 헤드라인 데이터에는 시작 토큰과 종료 토큰을 추가한다.\n",
    "data['decoder_input'] = data['headlines'].apply(lambda x : 'sostoken '+ x)\n",
    "data['decoder_target'] = data['headlines'].apply(lambda x : x + ' eostoken')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "YSxIv9vgf17n"
   },
   "outputs": [],
   "source": [
    "encoder_input = np.array(data['text']) # 인코더의 입력\n",
    "decoder_input = np.array(data['decoder_input']) # 디코더의 입력\n",
    "decoder_target = np.array(data['decoder_target']) # 디코더의 레이블"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u0H2fKaAgRZ8"
   },
   "source": [
    "## 훈련 & 테스트 데이터 스플릿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FslRV2gugLQC",
    "outputId": "e024069c-cb13-4ae4-e919-b6592d30ca4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23966 54020 15969 ... 39861 63162 26705]\n"
     ]
    }
   ],
   "source": [
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "3XaOM8zngXG4"
   },
   "outputs": [],
   "source": [
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8UfhWr4IgaZF",
    "outputId": "f281cdc6-b27d-45a4-86b4-976723980aef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터의 수 : 16382\n"
     ]
    }
   ],
   "source": [
    "# 8 : 2 로 데이터 분리\n",
    "n_of_val = int(len(encoder_input)*0.2)\n",
    "print('테스트 데이터의 수 :', n_of_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GbQHueQYgh9S",
    "outputId": "92b2383f-6957-4421-c3c3-cfa01d54ca1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 개수 : 65532\n",
      "훈련 레이블의 개수 : 65532\n",
      "테스트 데이터의 개수 : 16382\n",
      "테스트 레이블의 개수 : 16382\n"
     ]
    }
   ],
   "source": [
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :', len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :', len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :', len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9RB-bsSihFTR"
   },
   "source": [
    "## 단어 집합(vocabulary) 만들기 및 정수 인코딩 - text\n",
    "  - Keras 토크나이저 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "AGlCY4wug2Lz"
   },
   "outputs": [],
   "source": [
    "src_tokenizer = Tokenizer() # 토크나이저 정의\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 입력된 데이터로부터 단어 집합 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7V3z5Q0BhB-_",
    "outputId": "38b3c194-aba8-4629-f160-46ba5a5fcfc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 63061\n",
      "등장 빈도가 6번 이하인 희귀 단어의 수: 43006\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 20055\n",
      "단어 집합에서 희귀 단어의 비율: 68.197459602607\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 3.8777839484222905\n"
     ]
    }
   ],
   "source": [
    "threshold = 7\n",
    "total_cnt = len(src_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in src_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cJc5Wp5fjfNM"
   },
   "source": [
    "### 단어 집합 내에서 희귀 단어의 비율이 68% 를 차지하나, 전체 훈련데이터 등장 빈도로 차지하는 비중은 3.9% 밖에 차지 하지 않음.\n",
    "  - 그래서 6회 이하의 단어는 빼고 훈련데이터에서 제거\n",
    "  - 단어 집합에서 희귀 단어를 제외시킬 경우 단어 집합의 크기가 2만개 이므로  단어 집합의 크기를 제한"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "lTrStJx6izax"
   },
   "outputs": [],
   "source": [
    "src_vocab = 20000\n",
    "src_tokenizer = Tokenizer(num_words=src_vocab) # 단어 집합의 크기를 20,000으로 제한\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 단어 집합 재생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[37, 657, 5284, 6258, 69, 1, 40, 3894, 3999, 253, 89, 43, 570, 651, 724, 113, 735, 9515, 8911, 10818, 1531, 70, 134, 67, 6258, 1, 8911, 807, 10, 1743, 1888, 40, 722, 9, 100, 17499, 3999], [2168, 837, 146, 277, 327, 1971, 1536, 161, 11, 7512, 79, 1, 5633, 8588, 23, 2036, 52, 2168, 2, 2322, 1660, 11872, 2966, 1, 791, 893, 358, 7774, 11], [2611, 368, 5852, 1014, 8749, 3650, 7153, 5510, 400, 9295, 121, 914, 115, 9754, 10517, 409, 950, 2611, 228, 4895, 1, 229, 1809, 97, 5510, 400, 9295, 9989, 420]]\n"
     ]
    }
   ],
   "source": [
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "encoder_input_train = src_tokenizer.texts_to_sequences(encoder_input_train) \n",
    "encoder_input_test = src_tokenizer.texts_to_sequences(encoder_input_test)\n",
    "\n",
    "# 잘 진행되었는지 샘플 출력\n",
    "print(encoder_input_train[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8p6pslM2kgMt"
   },
   "source": [
    "## 단어 집합(vocabulary) 만들기 및 정수 인코딩 - headlines\n",
    "  - Keras 토크나이저 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "OVerALcjkS_Y"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_44/2567310370.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtar_tokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtar_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_on_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_input_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras_preprocessing/text.py\u001b[0m in \u001b[0;36mfit_on_texts\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext_elem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext_elem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras_preprocessing/text.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext_elem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext_elem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "tar_tokenizer = Tokenizer()\n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rl19hiekktqP",
    "outputId": "c4776ce8-859b-4656-f664-a5620fe567b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 27541\n",
      "등장 빈도가 5번 이하인 희귀 단어의 수: 18228\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 9313\n",
      "단어 집합에서 희귀 단어의 비율: 66.18496060419011\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 6.758856101085133\n"
     ]
    }
   ],
   "source": [
    "threshold = 6\n",
    "total_cnt = len(tar_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in tar_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5GHYg6vUk8Ce"
   },
   "source": [
    "### 단어 집합 내에서 희귀 단어의 비율이 66% 를 차지하나, 전체 훈련데이터 등장 빈도로 차지하는 비중은 6.7% 밖에 차지 하지 않음.\n",
    "  - 그래서 5회 이하의 단어는 빼고 훈련데이터에서 제거\n",
    "  - 단어 집합에서 희귀 단어를 제외시킬 경우 단어 집합의 크기가 9000여개 이므로 단어 집합의 크기를 9000개로 제한"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w5guV3eRkxdj",
    "outputId": "51430417-2e7b-4c60-be40-fe2d6fe82d5d"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_44/2876114475.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtar_vocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m9000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtar_tokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtar_vocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtar_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_on_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_input_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtar_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_on_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_target_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras_preprocessing/text.py\u001b[0m in \u001b[0;36mfit_on_texts\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext_elem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext_elem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras_preprocessing/text.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext_elem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext_elem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "tar_vocab = 9000\n",
    "tar_tokenizer = Tokenizer(num_words=tar_vocab)\n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
    "tar_tokenizer.fit_on_texts(decoder_target_train)\n",
    "\n",
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "decoder_input_train = tar_tokenizer.texts_to_sequences(decoder_input_train)\n",
    "decoder_target_train = tar_tokenizer.texts_to_sequences(decoder_target_train)\n",
    "decoder_input_test = tar_tokenizer.texts_to_sequences(decoder_input_test)\n",
    "decoder_target_test = tar_tokenizer.texts_to_sequences(decoder_target_test)\n",
    "\n",
    "# 잘 변환되었는지 확인\n",
    "print('input')\n",
    "print('input ',decoder_input_train[:5])\n",
    "print('target')\n",
    "print('decoder ',decoder_target_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fks6XmbSlZs7",
    "outputId": "92c85df2-e0ef-4f64-848a-9b7d4188626d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삭제할 훈련 데이터의 개수 : 3\n",
      "삭제할 테스트 데이터의 개수 : 0\n",
      "훈련 데이터의 개수 : 65529\n",
      "훈련 레이블의 개수 : 65529\n",
      "테스트 데이터의 개수 : 16382\n",
      "테스트 레이블의 개수 : 16382\n"
     ]
    }
   ],
   "source": [
    "drop_train = [index for index, sentence in enumerate(decoder_input_train) if len(sentence) == 1]\n",
    "drop_test = [index for index, sentence in enumerate(decoder_input_test) if len(sentence) == 1]\n",
    "\n",
    "print('삭제할 훈련 데이터의 개수 :', len(drop_train))\n",
    "print('삭제할 테스트 데이터의 개수 :', len(drop_test))\n",
    "\n",
    "encoder_input_train = [sentence for index, sentence in enumerate(encoder_input_train) if index not in drop_train]\n",
    "decoder_input_train = [sentence for index, sentence in enumerate(decoder_input_train) if index not in drop_train]\n",
    "decoder_target_train = [sentence for index, sentence in enumerate(decoder_target_train) if index not in drop_train]\n",
    "\n",
    "encoder_input_test = [sentence for index, sentence in enumerate(encoder_input_test) if index not in drop_test]\n",
    "decoder_input_test = [sentence for index, sentence in enumerate(decoder_input_test) if index not in drop_test]\n",
    "decoder_target_test = [sentence for index, sentence in enumerate(decoder_target_test) if index not in drop_test]\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :', len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :', len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :', len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zvwP1it0m42t"
   },
   "source": [
    "## 패딩하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 395
    },
    "id": "1NTSj7BEmzcL",
    "outputId": "fc1ca7c0-8b08-4d61-9129-fd6ec4a5ece9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "encoder_input_train = pad_sequences(encoder_input_train, maxlen=text_max_len, padding='post')\n",
    "encoder_input_test = pad_sequences(encoder_input_test, maxlen=text_max_len, padding='post')\n",
    "decoder_input_train = pad_sequences(decoder_input_train, maxlen=headlines_max_len, padding='post')\n",
    "decoder_target_train = pad_sequences(decoder_target_train, maxlen=headlines_max_len, padding='post')\n",
    "decoder_input_test = pad_sequences(decoder_input_test, maxlen=headlines_max_len, padding='post')\n",
    "decoder_target_test = pad_sequences(decoder_target_test, maxlen=headlines_max_len, padding='post')\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jSf0hmAUm6LK"
   },
   "source": [
    "## 모델 설계하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "# 인코더 설계 시작\n",
    "embedding_dim = 128\n",
    "hidden_size = 256\n",
    "\n",
    "# 인코더\n",
    "encoder_inputs = Input(shape=(text_max_len,))\n",
    "\n",
    "# 인코더의 임베딩 층\n",
    "enc_emb = Embedding(src_vocab, embedding_dim)(encoder_inputs)\n",
    "\n",
    "# 인코더의 LSTM 1\n",
    "# encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4, recurrent_dropout = 0.4)\n",
    "encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "# 인코더의 LSTM 2\n",
    "encoder_lstm2 = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "# 인코더의 LSTM 3\n",
    "encoder_lstm3 = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_output3, state_h3, state_c3 = encoder_lstm3(encoder_output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 설계\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "# 디코더의 임베딩 층\n",
    "dec_emb_layer = Embedding(tar_vocab, embedding_dim)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 디코더의 LSTM\n",
    "# decoder_lstm = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.2)\n",
    "decoder_lstm = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=[state_h3, state_c3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 40)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 40, 128)      2560000     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, 40, 256), (N 394240      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   [(None, 40, 256), (N 525312      lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 128)    1152000     input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_5 (LSTM)                   [(None, 40, 256), (N 525312      lstm_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_6 (LSTM)                   [(None, None, 256),  394240      embedding_2[0][0]                \n",
      "                                                                 lstm_5[0][1]                     \n",
      "                                                                 lstm_5[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 9000)   2313000     lstm_6[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 7,864,104\n",
      "Trainable params: 7,864,104\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_outputs) \n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 어텐션 메커니즘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 40)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 40, 128)      2560000     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, 40, 256), (N 394240      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   [(None, 40, 256), (N 525312      lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 128)    1152000     input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_5 (LSTM)                   [(None, 40, 256), (N 525312      lstm_4[0][0]                     \n",
      "                                                                 lstm_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_6 (LSTM)                   [(None, None, 256),  394240      embedding_2[0][0]                \n",
      "                                                                 lstm_5[0][1]                     \n",
      "                                                                 lstm_5[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AdditiveAttent (None, None, 256)    256         lstm_6[0][0]                     \n",
      "                                                                 lstm_5[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 512)    0           lstm_6[0][0]                     \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 9000)   4617000     concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 10,168,360\n",
      "Trainable params: 10,168,360\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import AdditiveAttention\n",
    "\n",
    "# encoder_outputs를 정의해줍니다.\n",
    "encoder_outputs, state_h3, state_c3 = encoder_lstm3(encoder_output2)\n",
    "# 어텐션 층(어텐션 함수)\n",
    "attn_layer = AdditiveAttention(name='attention_layer')\n",
    "\n",
    "# 인코더와 디코더의 모든 time step의 hidden state를 어텐션 층에 전달하고 결과를 리턴\n",
    "attn_out = attn_layer([decoder_outputs, encoder_outputs])\n",
    "\n",
    "\n",
    "# 어텐션의 결과와 디코더의 hidden state들을 연결\n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_concat_input)\n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 훈련하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "64/64 [==============================] - 52s 677ms/step - loss: 2.1537 - val_loss: 4.6226\n",
      "Epoch 2/20\n",
      "64/64 [==============================] - 42s 661ms/step - loss: 2.0622 - val_loss: 4.6363\n",
      "Epoch 3/20\n",
      "64/64 [==============================] - 42s 662ms/step - loss: 2.0107 - val_loss: 4.6492\n",
      "Epoch 00003: early stopping\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
    "# es = EarlyStopping(monitor='val_loss', patience=2, verbose=1)\n",
    "history = model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n",
    "          validation_data=([encoder_input_test, decoder_input_test], decoder_target_test), \\\n",
    "          batch_size=1024, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 인퍼런스 모델 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_index_to_word = src_tokenizer.index_word # 원문 단어 집합에서 정수 -> 단어를 얻음\n",
    "tar_word_to_index = tar_tokenizer.word_index # 요약 단어 집합에서 단어 -> 정수를 얻음\n",
    "tar_index_to_word = tar_tokenizer.index_word # 요약 단어 집합에서 정수 -> 단어를 얻음\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 설계\n",
    "encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state_h1, state_c1])\n",
    "\n",
    "# 이전 시점의 상태들을 저장하는 텐서\n",
    "decoder_state_input_h = Input(shape=(hidden_size,))\n",
    "decoder_state_input_c = Input(shape=(hidden_size,))\n",
    "\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용. 이는 뒤의 함수 decode_sequence()에 구현\n",
    "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태인 state_h와 state_c를 버리지 않음.\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어텐션 함수\n",
    "decoder_hidden_state_input = Input(shape=(text_max_len, hidden_size))\n",
    "attn_out_inf = attn_layer([decoder_outputs2, decoder_hidden_state_input])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_outputs2 = decoder_softmax_layer(decoder_inf_concat) \n",
    "\n",
    "# 최종 디코더 모델\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs2] + [state_h2, state_c2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "\n",
    "     # <SOS>에 해당하는 토큰 생성\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = tar_word_to_index['sostoken']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition: # stop_condition이 True가 될 때까지 루프 반복\n",
    "\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = tar_index_to_word[sampled_token_index]\n",
    "\n",
    "        if (sampled_token!='eostoken'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "        #  <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_token == 'eostoken'  or len(decoded_sentence.split()) >= (summary_max_len-1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 길이가 1인 타겟 시퀀스를 업데이트\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # 상태를 업데이트 합니다.\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 테스트 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2text(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if (i!=0):\n",
    "            temp = temp + src_index_to_word[i]+' '\n",
    "    return temp\n",
    "\n",
    "# 요약문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2summary(input_seq):\n",
    "    # [[YOUR CODE]]\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if (i != 0 and i != tar_word_to_index['sostoken'] and i != tar_word_to_index['eostoken']):\n",
    "            temp = temp + tar_index_to_word[i] + ' '\n",
    "    return temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원문 : uttar pradesh minister op rajbhar repaired metre long road outside residence ahead son wedding reception authorities ignored pleas rajbhar said requested government road two months ago avail added option repair ahead function sunday \n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'sostoken'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_44/2384696985.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"원문 :\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq2text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_input_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"실제 요약 :\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq2summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_input_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"예측 요약 :\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_input_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_max_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_44/2795199116.py\u001b[0m in \u001b[0;36mseq2summary\u001b[0;34m(input_seq)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mtemp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_seq\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtar_word_to_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sostoken'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtar_word_to_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eostoken'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtar_index_to_word\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'sostoken'"
     ]
    }
   ],
   "source": [
    "for i in range(50, 100):\n",
    "    print(\"원문 :\", seq2text(encoder_input_test[i]))\n",
    "    print(\"실제 요약 :\", seq2summary(decoder_input_test[i]))\n",
    "    print(\"예측 요약 :\", decode_sequence(encoder_input_test[i].reshape(1, text_max_len)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 추출적 요약 해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from summa.summarizer import summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = requests.get('http://rare-technologies.com/the_matrix_synopsis.txt').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The screen is filled with green, cascading code which gives way to the title, The Matrix.\r\n",
      "\r\n",
      "A phone rings and text appears on the screen: \"Call trans opt: received. 2-19-98 13:24:18 REC: Log>\" As a conversation takes place between Trinity (Carrie-Anne Moss) and Cypher (Joe Pantoliano), two free humans, a table of random green numbers are being scanned and individual numbers selected, creating a series of digits not unlike an ordinary phone number, as if a code is being deciphered or a call is being traced.\r\n",
      "\r\n",
      "Trinity discusses some unknown person. Cypher taunts Trinity, suggesting she enjoys watching him. Trinity counters that \"Morpheus (Laurence Fishburne) says he may be 'the One',\" just as the sound of a number being selected alerts Trinity that someone may be tracing their call. She ends the call.\r\n",
      "\r\n",
      "Armed policemen move down a darkened, decrepit hallway in the Heart O' the City Hotel, their flashlight beam bouncing just ahead of them. They come to room 303, kick down the door and find a woman dressed in black, facing away from them. It's Trinity. She brings her hands up from the laptop she's working on at their command.\r\n",
      "\r\n",
      "Outside the hotel a car drives up and three agents appear in neatly pressed black suits. They are Agent Smith (Hugo Weaving), Agent Brown (Paul Goddard), and Agent Jones (Robert Taylor). Agent Smith and the presiding police lieutenant argue. Agent Smith admonishes the policeman that they were given specific orders to contact the agents first, for their\n"
     ]
    }
   ],
   "source": [
    "print(text[:1500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "Morpheus, Trinity, Neo, Apoc, Switch, Mouse and Cypher are jacked into the Matrix.\n",
      "Trinity brings the helicopter down to the floor that Morpheus is on and Neo opens fire on the three Agents.\n"
     ]
    }
   ],
   "source": [
    "print('Summary:')\n",
    "print(summarize(text, ratio=0.005))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "name": "Colaboratory에 오신 것을 환영합니다",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
